{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ConditionalGAN as cGAN\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "decay = 1.00004\n",
    "batch_size = 100\n",
    "num_epoch = 100\n",
    "dir_name = \"CGAN_results\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load DataSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data :  60000\n",
      "number of test data :  10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = './data/',\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root = './data/',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "\n",
    "print('number of training data : ', len(train_data))\n",
    "print('number of test data : ', len(test_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,batch_size = batch_size, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,batch_size = batch_size, shuffle = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-setting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "generator = cGAN.Generator().to(device)\n",
    "discriminator = cGAN.Discriminator().to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "DisOptimizer = torch.optim.SGD(generator.parameters(), lr=lr, momentum=0.5, weight_decay=decay)\n",
    "GenOptimizer = torch.optim.SGD(generator.parameters(), lr=lr, momentum=0.5, weight_decay=decay)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 29/600 [00:05<01:42,  5.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12920\\4182150015.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[0mdisLoss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mfake_loss\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mreal_loss\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 50\u001B[1;33m         \u001B[0mdisLoss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     51\u001B[0m         \u001B[0mDisOptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\cGAN\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    394\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 396\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\envs\\cGAN\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    173\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 175\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    176\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    177\u001B[0m def grad(\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    bar = tqdm(train_loader)\n",
    "    train_loss = []\n",
    "    for i, (images, labels) in enumerate(bar):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Create Real and Fake Label\n",
    "        real_label = torch.full((batch_size, 1), 1, dtype=torch.float32).to(device)\n",
    "        fake_label = torch.full((batch_size, 1), 0, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Flatten MNIST images\n",
    "        real_images = images.reshape(batch_size, -1).to(device)\n",
    "\n",
    "        # +---------------------+\n",
    "        # |   train Generator   |\n",
    "        # +---------------------+\n",
    "\n",
    "        # Initialize gradient\n",
    "        GenOptimizer.zero_grad()\n",
    "        DisOptimizer.zero_grad()\n",
    "\n",
    "        # Create Noise Vector z\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "\n",
    "        # Training Generator\n",
    "        fake_images = generator(z, labels)\n",
    "\n",
    "        # Get Loss From Real Image\n",
    "        genLoss = criterion(discriminator(fake_images, labels), real_label)\n",
    "\n",
    "        genLoss.backward()\n",
    "        GenOptimizer.step()\n",
    "\n",
    "        # +---------------------+\n",
    "        # | train Discriminator |\n",
    "        # +---------------------+\n",
    "\n",
    "        # Initialize gradient\n",
    "        GenOptimizer.zero_grad()\n",
    "        DisOptimizer.zero_grad()\n",
    "\n",
    "        # Create Noise Vector z\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_images = generator(z, labels)\n",
    "\n",
    "        fake_loss = criterion(discriminator(fake_images, labels), fake_label)\n",
    "        real_loss = criterion(discriminator(real_images, labels), real_label)\n",
    "        disLoss = (fake_loss + real_loss) / 2\n",
    "\n",
    "        disLoss.backward()\n",
    "        DisOptimizer.step()\n",
    "\n",
    "        d_performance = discriminator(fake_images, labels).mean()\n",
    "        g_performance = discriminator(real_images, labels).mean()\n",
    "\n",
    "        if (i + 1) % 150 == 0:\n",
    "            print(\"Epoch [ {}/{} ]  Step [ {}/{} ]  d_loss : {:.5f}  g_loss : {:.5f}\".format(epoch + 1, num_epoch, i+1, len(train_loader), disLoss.item(), genLoss.item()))\n",
    "    # print discriminator & generator's performance\n",
    "    print(\" Epoch {}'s discriminator performance : {:.2f}  generator performance : {:.2f}\".format(epoch + 1, d_performance, g_performance))\n",
    "\n",
    "    # Save fake images in each epoch\n",
    "    samples = fake_images.reshape(batch_size, 1, 28, 28)\n",
    "    save_image(samples, os.path.join(dir_name, 'CGAN_fake_samples{}.png'.format(epoch + 1)))\n",
    "    # print(\"label of 'CGAN_fake_samples{}.png' is {}\".format(epoch + 1, label))\n",
    "\n",
    "    # Draw real labels on fake sample images\n",
    "    # If you got error about this, you can remove lines below\n",
    "    fake_sample_image = Image.open(\"{}/CGAN_fake_samples{}.png\".format(dir_name, epoch + 1))\n",
    "    font = ImageFont.truetype(\"arial.ttf\", 17)\n",
    "\n",
    "    label = label.tolist()\n",
    "    label = label[:10]\n",
    "    label = [str(l) for l in label]\n",
    "\n",
    "    label_text = \", \".join(label)\n",
    "    label_text = \"Conditional GAN -\\n\" \\\n",
    "                 \"first 10 labels in this image :\\n\" + label_text\n",
    "\n",
    "    image_edit = ImageDraw.Draw(fake_sample_image)\n",
    "    image_edit.multiline_text(xy=(15, 300),\n",
    "                              text=label_text,\n",
    "                              fill=(0, 255, 255),\n",
    "                              font=font,\n",
    "                              stroke_width= 4,\n",
    "                              stroke_fill=(0, 0, 0))\n",
    "    fake_sample_image.save(\"{}/CGAN_fake_samples{}.png\".format(dir_name, epoch + 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
